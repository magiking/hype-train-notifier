{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models to use for prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This will help us work with our data easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chat: \n",
    "    def __init__(self, chat, label):\n",
    "        self.chat = chat\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Append all of our data to a single tuple to be used with our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1025\n",
      "2200\n"
     ]
    }
   ],
   "source": [
    "hypechat = './hype-train-notifier/comments/comments.txt'\n",
    "hypelabels = './hype-train-notifier/comments/hypelabel.txt'\n",
    "normalchat = './hype-train-notifier/comments/noexcite.txt'\n",
    "normallabels = './hype-train-notifier/comments/nohypelabel.txt'\n",
    "\n",
    "hype = []\n",
    "\n",
    "# Append both our hype data and normal data into a single tuple for \n",
    "with open(hypechat, encoding=\"utf-8\") as h, open(hypelabels, encoding=\"utf-8\") as l:\n",
    "    for line, label in zip(h, l):\n",
    "        hype.append(Chat(line.strip(), label.strip()))\n",
    "print(len(hype))\n",
    "with open(normalchat, encoding=\"utf-8\") as h, open(normallabels, encoding=\"utf-8\") as l:\n",
    "    for line, label in zip(h, l):\n",
    "        hype.append(Chat(line.strip(), label.strip()))\n",
    "print(len(hype))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WWWWWWWWWW'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hype[58].chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split our train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(hype, test_size=0.20, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [x.chat for x in train]\n",
    "train_y = [x.label for x in train]\n",
    "\n",
    "test_x = [x.chat for x in test]\n",
    "test_y = [x.label for x in test]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create bag of words vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "train_xv = vectorizer.fit_transform(train_x)\n",
    "\n",
    "test_xv = vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will try using Logistic Regression & Naive Bayes and compare our results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAHAHAHA\n",
      "['hype']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_l = LogisticRegression(random_state=0).fit(train_xv, train_y)\n",
    "\n",
    "# Random sample\n",
    "print(test_x[38])\n",
    "print(clf_l.predict(test_xv[38]))\n",
    "\n",
    "#for i in range(len(test_x)):\n",
    "#    print(test_x[i])\n",
    "#    print(clf_l.predict(test_xv[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive bayes that we will train and use with our program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAHAHAHA\n",
      "['hype']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clfNB = BernoulliNB()\n",
    "\n",
    "clfNB.fit(train_xv.todense(), train_y)\n",
    "\n",
    "print(test_x[38])\n",
    "print(clfNB.predict(test_xv[38]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8204545454545454\n",
      "0.759090909090909\n"
     ]
    }
   ],
   "source": [
    "print(clf_l.score(test_xv, test_y))\n",
    "print(clfNB.score(test_xv, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81755196, 0.82326622])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(test_y, clf_l.predict(test_xv), average=None, labels =[\"hype\", \"not hype\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78367347, 0.72820513])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test_y, clfNB.predict(test_xv), average=None, labels =[\"hype\", \"not hype\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
