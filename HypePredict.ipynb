{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models to use for prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This will help us work with our data easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chat: \n",
    "    def __init__(self, chat, label):\n",
    "        self.chat = chat\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Append all of our data to a single tuple to be used with our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1025\n",
      "2200\n"
     ]
    }
   ],
   "source": [
    "hypechat = './comments/comments.txt'\n",
    "hypelabels = './labels/hypelabel.txt'\n",
    "normalchat = './comments/noexcite.txt'\n",
    "normallabels = './labels/nohypelabel.txt'\n",
    "\n",
    "hype = []\n",
    "\n",
    "# Append both our hype data and normal data into a single tuple for \n",
    "with open(hypechat, encoding=\"utf-8\") as h, open(hypelabels, encoding=\"utf-8\") as l:\n",
    "    for line, label in zip(h, l):\n",
    "        hype.append(Chat(line.strip(), label.strip()))\n",
    "print(len(hype))\n",
    "with open(normalchat, encoding=\"utf-8\") as h, open(normallabels, encoding=\"utf-8\") as l:\n",
    "    for line, label in zip(h, l):\n",
    "        hype.append(Chat(line.strip(), label.strip()))\n",
    "print(len(hype))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WWWWWWWWWW'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hype[58].chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split our train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(hype, test_size=0.20, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [x.chat for x in train]\n",
    "train_y = [x.label for x in train]\n",
    "\n",
    "test_x = [x.chat for x in test]\n",
    "test_y = [x.label for x in test]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create bag of words vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "train_xv = vectorizer.fit_transform(train_x)\n",
    "\n",
    "test_xv = vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will try using Logistic Regression & Naive Bayes and compare our results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAHAHAHA\n",
      "['hype']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_l = LogisticRegression(random_state=0).fit(train_xv, train_y)\n",
    "\n",
    "# Random sample\n",
    "print(test_x[38])\n",
    "print(clf_l.predict(test_xv[38]))\n",
    "\n",
    "#for i in range(len(test_x)):\n",
    "#    print(test_x[i])\n",
    "#    print(clf_l.predict(test_xv[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive bayes that we will train and use with our program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAHAHAHA\n",
      "['hype']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clfNB = BernoulliNB()\n",
    "\n",
    "clfNB.fit(train_xv.todense(), train_y)\n",
    "\n",
    "print(test_x[38])\n",
    "print(clfNB.predict(test_xv[38]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8204545454545454\n",
      "0.759090909090909\n"
     ]
    }
   ],
   "source": [
    "print(clf_l.score(test_xv, test_y))\n",
    "print(clfNB.score(test_xv, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81755196, 0.82326622])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(test_y, clf_l.predict(test_xv), average=None, labels =[\"hype\", \"not hype\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78367347, 0.72820513])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test_y, clfNB.predict(test_xv), average=None, labels =[\"hype\", \"not hype\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    " \n",
    "hype_files = [f for f in listdir('./hypstreams/') if isfile(join('./hypstreams/', f))]\n",
    "reg_files  = [f for f in listdir('./regstreams/') if isfile(join('./regstreams/', f))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stream():\n",
    "    def __init__(self, name, comments,\n",
    "                 stream_label='hype',\n",
    "                 predictions=[], states=[]):\n",
    "        self.name = name \n",
    "        self.comments = comments\n",
    "        self.stream_label = stream_label\n",
    "        self.predictions = predictions\n",
    "        self.states = states\n",
    "\n",
    "    def printStateResults(self):\n",
    "        # majority state\n",
    "        majority = 'not hype'\n",
    "        count_hype_state = len([ x for x in self.states if x=='hype' ]) \n",
    "        count_not_state = len(self.states) - count_hype_state\n",
    "        if count_hype_state > count_not_state:\n",
    "            majority = 'hype'\n",
    "        per_hype = count_hype_state/len(self.states)\n",
    "        print(self.name, self.stream_label, majority, per_hype, count_hype_state, sep=',')\n",
    "        \n",
    "    \n",
    "    def printPredictionResults(self):\n",
    "        # majority prediction\n",
    "        majority = 'not hype'\n",
    "        count_hype_prediction = len([ x for x in self.predictions if x=='hype' ]) \n",
    "        count_not_prediction = len(self.predictions) - count_hype_prediction\n",
    "        if count_hype_prediction > count_not_prediction:\n",
    "            majority = 'hype'\n",
    "        per_hype = count_hype_prediction/len(self.predictions)\n",
    "        print(self.name, self.stream_label, majority, per_hype, count_hype_prediction, sep=',')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setStreamStates(stream, threshold=10):\n",
    "    hype_count = 0\n",
    "    states = []\n",
    "    hype_counts = []\n",
    "    for p in stream.predictions:\n",
    "        # increment the count\n",
    "        if p == 'hype':\n",
    "            hype_count += 1\n",
    "        else:\n",
    "            if hype_count > 0:\n",
    "                hype_count -= 1\n",
    "        # set the state\n",
    "        if hype_count >= threshold:\n",
    "            state = 'hype'\n",
    "        else:\n",
    "            state = 'not hype'\n",
    "        states.append(state)\n",
    "        hype_counts.append(hype_count)\n",
    "        \n",
    "    stream.states=states\n",
    "    stream.hype_counts=hype_counts\n",
    "         \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "hype_streams = []\n",
    "reg_streams = []\n",
    "# loop over our streams and build stream objects\n",
    "for fname in hype_files:\n",
    "    with open(join('./hypstreams/', fname)) as f:\n",
    "        comments = f.readlines()\n",
    "        vectorized = vectorizer.transform(comments)\n",
    "        predictions = clf_l.predict(vectorized)\n",
    "        hype_streams.append(Stream(fname, comments, stream_label='hype', predictions=predictions))\n",
    "\n",
    "for fname in reg_files:\n",
    "    with open(join('./regstreams/', fname)) as f:\n",
    "        comments = f.readlines()\n",
    "        vectorized = vectorizer.transform(comments)\n",
    "        predictions = clf_l.predict(vectorized)\n",
    "        reg_streams.append(Stream(fname, comments, stream_label='not hype', predictions=predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**hype stream state results\n",
      "hyp-TenZ-11-22.txt,hype,not hype,0.0,0\n",
      "hyp-esl_csgo-11-22.txt,hype,hype,0.910828025477707,143\n",
      "hyp-timthetatman-11-22.txt,hype,hype,0.9133858267716536,116\n",
      "hyp-moistcr1tikal-11-15.txt,hype,hype,0.7578947368421053,144\n",
      "hypestreams.txt,hype,not hype,0.0,0\n",
      "hyp-GMHikaru-11-22.txt,hype,hype,0.9340277777777778,269\n",
      "hyp-eslcsgo2-11-22.txt,hype,hype,0.9142857142857143,96\n",
      "hyp-loltyler1-11-22.txt,hype,hype,0.8512396694214877,103\n",
      "\n",
      "**not hype stream state results\n",
      "reg-silentgarrett-11-21.txt,not hype,not hype,0.0,0\n",
      "reg-gomisworld-11-21.txt,not hype,not hype,0.0,0\n",
      "reg-aforestlife-11-21.txt,not hype,not hype,0.0,0\n",
      "reg-keys-11-21.txt,not hype,not hype,0.0,0\n",
      "reg-hologramdreams-11-21.txt,not hype,not hype,0.0,0\n",
      "reg-coffeewithbee-11-21.txt,not hype,not hype,0.0,0\n",
      "reg-sudarezz-11-20.txt,not hype,not hype,0.0,0\n"
     ]
    }
   ],
   "source": [
    "# calculate the states\n",
    "threshold=10\n",
    "for stream in hype_streams:\n",
    "    setStreamStates(stream, threshold=threshold)\n",
    "for stream in reg_streams:\n",
    "    setStreamStates(stream, threshold=threshold)\n",
    "    \n",
    "\n",
    "# print results\n",
    "print('**hype stream state results')\n",
    "for stream in hype_streams:\n",
    "    stream.printStateResults()\n",
    "\n",
    "print()\n",
    "print('**not hype stream state results')\n",
    "for stream in reg_streams:\n",
    "    stream.printStateResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**hype stream prediction results\n",
      "hyp-TenZ-11-22.txt,hype,hype,1.0,3\n",
      "hyp-esl_csgo-11-22.txt,hype,hype,0.9554140127388535,150\n",
      "hyp-timthetatman-11-22.txt,hype,hype,0.8582677165354331,109\n",
      "hyp-moistcr1tikal-11-15.txt,hype,hype,0.8052631578947368,153\n",
      "hypestreams.txt,hype,not hype,0.4666666666666667,7\n",
      "hyp-GMHikaru-11-22.txt,hype,hype,0.8993055555555556,259\n",
      "hyp-eslcsgo2-11-22.txt,hype,hype,0.9047619047619048,95\n",
      "hyp-loltyler1-11-22.txt,hype,hype,0.9338842975206612,113\n",
      "\n",
      "**not hype stream prediction results\n",
      "reg-silentgarrett-11-21.txt,not hype,not hype,0.44680851063829785,21\n",
      "reg-gomisworld-11-21.txt,not hype,not hype,0.16,12\n",
      "reg-aforestlife-11-21.txt,not hype,not hype,0.24,30\n",
      "reg-keys-11-21.txt,not hype,not hype,0.2846153846153846,37\n",
      "reg-hologramdreams-11-21.txt,not hype,not hype,0.38953488372093026,67\n",
      "reg-coffeewithbee-11-21.txt,not hype,not hype,0.28688524590163933,35\n",
      "reg-sudarezz-11-20.txt,not hype,not hype,0.484375,31\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "print('**hype stream prediction results')\n",
    "for stream in hype_streams:\n",
    "    stream.printPredictionResults()\n",
    "\n",
    "print()\n",
    "print('**not hype stream prediction results')\n",
    "for stream in reg_streams:\n",
    "    stream.printPredictionResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time,hype count,state,prediction\n",
      "0,1,not hype,hype\n",
      "1,2,not hype,hype\n",
      "2,1,not hype,not hype\n",
      "3,0,not hype,not hype\n",
      "4,0,not hype,not hype\n",
      "5,1,not hype,hype\n",
      "6,0,not hype,not hype\n",
      "7,1,not hype,hype\n",
      "8,2,not hype,hype\n",
      "9,3,not hype,hype\n",
      "10,4,not hype,hype\n",
      "11,3,not hype,not hype\n",
      "12,2,not hype,not hype\n",
      "13,3,not hype,hype\n",
      "14,2,not hype,not hype\n",
      "15,3,not hype,hype\n",
      "16,2,not hype,not hype\n",
      "17,1,not hype,not hype\n",
      "18,2,not hype,hype\n",
      "19,1,not hype,not hype\n",
      "20,2,not hype,hype\n",
      "21,3,not hype,hype\n",
      "22,4,not hype,hype\n",
      "23,5,not hype,hype\n",
      "24,4,not hype,not hype\n",
      "25,3,not hype,not hype\n",
      "26,4,not hype,hype\n",
      "27,3,not hype,not hype\n",
      "28,4,not hype,hype\n",
      "29,3,not hype,not hype\n",
      "30,2,not hype,not hype\n",
      "31,3,not hype,hype\n",
      "32,4,not hype,hype\n",
      "33,5,not hype,hype\n",
      "34,4,not hype,not hype\n",
      "35,5,not hype,hype\n",
      "36,4,not hype,not hype\n",
      "37,5,not hype,hype\n",
      "38,4,not hype,not hype\n",
      "39,5,not hype,hype\n",
      "40,6,not hype,hype\n",
      "41,5,not hype,not hype\n",
      "42,6,not hype,hype\n",
      "43,7,not hype,hype\n",
      "44,8,not hype,hype\n",
      "45,9,not hype,hype\n",
      "46,10,hype,hype\n",
      "47,11,hype,hype\n",
      "48,12,hype,hype\n",
      "49,13,hype,hype\n",
      "50,14,hype,hype\n",
      "51,15,hype,hype\n",
      "52,14,hype,not hype\n",
      "53,15,hype,hype\n",
      "54,14,hype,not hype\n",
      "55,15,hype,hype\n",
      "56,14,hype,not hype\n",
      "57,13,hype,not hype\n",
      "58,14,hype,hype\n",
      "59,15,hype,hype\n",
      "60,16,hype,hype\n",
      "61,17,hype,hype\n",
      "62,18,hype,hype\n",
      "63,19,hype,hype\n",
      "64,20,hype,hype\n",
      "65,21,hype,hype\n",
      "66,22,hype,hype\n",
      "67,23,hype,hype\n",
      "68,22,hype,not hype\n",
      "69,23,hype,hype\n",
      "70,24,hype,hype\n",
      "71,25,hype,hype\n",
      "72,26,hype,hype\n",
      "73,27,hype,hype\n",
      "74,28,hype,hype\n",
      "75,29,hype,hype\n",
      "76,30,hype,hype\n",
      "77,29,hype,not hype\n",
      "78,30,hype,hype\n",
      "79,31,hype,hype\n",
      "80,32,hype,hype\n",
      "81,33,hype,hype\n",
      "82,34,hype,hype\n",
      "83,35,hype,hype\n",
      "84,36,hype,hype\n",
      "85,37,hype,hype\n",
      "86,38,hype,hype\n",
      "87,39,hype,hype\n",
      "88,40,hype,hype\n",
      "89,41,hype,hype\n",
      "90,42,hype,hype\n",
      "91,43,hype,hype\n",
      "92,44,hype,hype\n",
      "93,45,hype,hype\n",
      "94,46,hype,hype\n",
      "95,47,hype,hype\n",
      "96,46,hype,not hype\n",
      "97,47,hype,hype\n",
      "98,48,hype,hype\n",
      "99,49,hype,hype\n",
      "100,50,hype,hype\n",
      "101,51,hype,hype\n",
      "102,52,hype,hype\n",
      "103,53,hype,hype\n",
      "104,54,hype,hype\n",
      "105,55,hype,hype\n",
      "106,56,hype,hype\n",
      "107,55,hype,not hype\n",
      "108,56,hype,hype\n",
      "109,55,hype,not hype\n",
      "110,56,hype,hype\n",
      "111,57,hype,hype\n",
      "112,58,hype,hype\n",
      "113,59,hype,hype\n",
      "114,60,hype,hype\n",
      "115,61,hype,hype\n",
      "116,62,hype,hype\n",
      "117,63,hype,hype\n",
      "118,64,hype,hype\n",
      "119,65,hype,hype\n",
      "120,66,hype,hype\n",
      "121,67,hype,hype\n",
      "122,68,hype,hype\n",
      "123,67,hype,not hype\n",
      "124,68,hype,hype\n",
      "125,69,hype,hype\n",
      "126,68,hype,not hype\n",
      "127,67,hype,not hype\n",
      "128,68,hype,hype\n",
      "129,69,hype,hype\n",
      "130,70,hype,hype\n",
      "131,71,hype,hype\n",
      "132,72,hype,hype\n",
      "133,73,hype,hype\n",
      "134,74,hype,hype\n",
      "135,75,hype,hype\n",
      "136,76,hype,hype\n",
      "137,77,hype,hype\n",
      "138,78,hype,hype\n",
      "139,79,hype,hype\n",
      "140,80,hype,hype\n",
      "141,81,hype,hype\n",
      "142,82,hype,hype\n",
      "143,83,hype,hype\n",
      "144,84,hype,hype\n",
      "145,83,hype,not hype\n",
      "146,84,hype,hype\n",
      "147,85,hype,hype\n",
      "148,86,hype,hype\n",
      "149,87,hype,hype\n",
      "150,88,hype,hype\n",
      "151,89,hype,hype\n",
      "152,90,hype,hype\n",
      "153,89,hype,not hype\n",
      "154,90,hype,hype\n",
      "155,89,hype,not hype\n",
      "156,88,hype,not hype\n",
      "157,89,hype,hype\n",
      "158,90,hype,hype\n",
      "159,91,hype,hype\n",
      "160,92,hype,hype\n",
      "161,93,hype,hype\n",
      "162,94,hype,hype\n",
      "163,95,hype,hype\n",
      "164,96,hype,hype\n",
      "165,97,hype,hype\n",
      "166,98,hype,hype\n",
      "167,99,hype,hype\n",
      "168,100,hype,hype\n",
      "169,101,hype,hype\n",
      "170,102,hype,hype\n",
      "171,103,hype,hype\n",
      "172,104,hype,hype\n",
      "173,105,hype,hype\n",
      "174,106,hype,hype\n",
      "175,107,hype,hype\n",
      "176,108,hype,hype\n",
      "177,109,hype,hype\n",
      "178,110,hype,hype\n",
      "179,111,hype,hype\n",
      "180,112,hype,hype\n",
      "181,111,hype,not hype\n",
      "182,112,hype,hype\n",
      "183,113,hype,hype\n",
      "184,114,hype,hype\n",
      "185,115,hype,hype\n",
      "186,116,hype,hype\n",
      "187,117,hype,hype\n",
      "188,118,hype,hype\n",
      "189,117,hype,not hype\n"
     ]
    }
   ],
   "source": [
    "for stream in hype_streams:\n",
    "    if 'moist' in stream.name:\n",
    "        print(\"time,hype count,state,prediction\")\n",
    "        for time in range(len(stream.states)):\n",
    "            print(time, stream.hype_counts[time], stream.states[time], stream.predictions[time], sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time,hype count,state,prediction\n",
      "0,0,not hype,not hype\n",
      "1,0,not hype,not hype\n",
      "2,0,not hype,not hype\n",
      "3,0,not hype,not hype\n",
      "4,1,not hype,hype\n",
      "5,0,not hype,not hype\n",
      "6,0,not hype,not hype\n",
      "7,1,not hype,hype\n",
      "8,2,not hype,hype\n",
      "9,1,not hype,not hype\n",
      "10,0,not hype,not hype\n",
      "11,1,not hype,hype\n",
      "12,2,not hype,hype\n",
      "13,3,not hype,hype\n",
      "14,2,not hype,not hype\n",
      "15,1,not hype,not hype\n",
      "16,2,not hype,hype\n",
      "17,1,not hype,not hype\n",
      "18,0,not hype,not hype\n",
      "19,0,not hype,not hype\n",
      "20,0,not hype,not hype\n",
      "21,0,not hype,not hype\n",
      "22,1,not hype,hype\n",
      "23,2,not hype,hype\n",
      "24,1,not hype,not hype\n",
      "25,0,not hype,not hype\n",
      "26,0,not hype,not hype\n",
      "27,0,not hype,not hype\n",
      "28,0,not hype,not hype\n",
      "29,1,not hype,hype\n",
      "30,0,not hype,not hype\n",
      "31,1,not hype,hype\n",
      "32,0,not hype,not hype\n",
      "33,1,not hype,hype\n",
      "34,0,not hype,not hype\n",
      "35,1,not hype,hype\n",
      "36,0,not hype,not hype\n",
      "37,1,not hype,hype\n",
      "38,2,not hype,hype\n",
      "39,3,not hype,hype\n",
      "40,4,not hype,hype\n",
      "41,5,not hype,hype\n",
      "42,6,not hype,hype\n",
      "43,7,not hype,hype\n",
      "44,6,not hype,not hype\n",
      "45,5,not hype,not hype\n",
      "46,6,not hype,hype\n"
     ]
    }
   ],
   "source": [
    "for stream in reg_streams:\n",
    "    if 'garrett' in stream.name:\n",
    "        print(\"time,hype count,state,prediction\")\n",
    "        for time in range(len(stream.states)):\n",
    "            print(time, stream.hype_counts[time], stream.states[time], stream.predictions[time], sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "name": "HypePredict.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
